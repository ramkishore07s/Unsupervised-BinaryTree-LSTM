{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "import basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryTreeLSTMLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(BinaryTreeLSTMLayer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.comp_linear = nn.Linear(in_features=2 * hidden_dim,\n",
    "                                     out_features=5 * hidden_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.orthogonal_(self.comp_linear.weight.data)\n",
    "        init.constant_(self.comp_linear.bias.data, val=0)\n",
    "\n",
    "    def forward(self, l=None, r=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            l: A (h_l, c_l) tuple, where each value has the size\n",
    "                (batch_size, max_length, hidden_dim).\n",
    "            r: A (h_r, c_r) tuple, where each value has the size\n",
    "                (batch_size, max_length, hidden_dim).\n",
    "        Returns:\n",
    "            h, c: The hidden and cell state of the composed parent,\n",
    "                each of which has the size\n",
    "                (batch_size, max_length - 1, hidden_dim).\n",
    "        \"\"\"\n",
    "\n",
    "        hl, cl = l\n",
    "        hr, cr = r\n",
    "        hlr_cat = torch.cat([hl, hr], dim=2)\n",
    "        treelstm_vector = self.comp_linear(hlr_cat)\n",
    "        i, fl, fr, u, o = treelstm_vector.chunk(chunks=5, dim=2)\n",
    "        c = (cl*(fl + 1).sigmoid() + cr*(fr + 1).sigmoid()\n",
    "             + u.tanh()*i.sigmoid())\n",
    "        h = o.sigmoid() * c.tanh()\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryTreeLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, word_dim, hidden_dim, use_leaf_rnn, intra_attention,\n",
    "                 gumbel_temperature, bidirectional):\n",
    "        super(BinaryTreeLSTM, self).__init__()\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gumbel_temperature = gumbel_temperature\n",
    "        self.word_linear = nn.Linear(in_features=word_dim, out_features=2 * hidden_dim)\n",
    "        self.treelstm_layer = BinaryTreeLSTMLayer(hidden_dim)\n",
    "        self.comp_query = nn.Parameter(torch.FloatTensor(hidden_dim))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.treelstm_layer.reset_parameters()\n",
    "        init.normal_(self.comp_query.data, mean=0, std=0.01)\n",
    "        \n",
    "    @staticmethod\n",
    "    def update_state(old_state, new_state, done_mask):\n",
    "        old_h, old_c = old_state\n",
    "        new_h, new_c = new_state\n",
    "        done_mask = done_mask.float().unsqueeze(1).unsqueeze(2)\n",
    "        h = done_mask * new_h + (1 - done_mask) * old_h[:, :-1, :]\n",
    "        c = done_mask * new_c + (1 - done_mask) * old_c[:, :-1, :]\n",
    "        return h, c\n",
    "    \n",
    "    def select_composition(self, old_state, new_state, mask):\n",
    "        new_h, new_c = new_state\n",
    "        old_h, old_c = old_state\n",
    "        old_h_left, old_h_right = old_h[:, :-1, :], old_h[:, 1:, :]\n",
    "        old_c_left, old_c_right = old_c[:, :-1, :], old_c[:, 1:, :]\n",
    "        comp_weights = (self.comp_query * new_h).sum(-1)\n",
    "        comp_weights = comp_weights / math.sqrt(self.hidden_dim)\n",
    "        if self.training:\n",
    "            select_mask = basic.st_gumbel_softmax(\n",
    "                logits=comp_weights, temperature=self.gumbel_temperature,\n",
    "                mask=mask)\n",
    "        else:\n",
    "            select_mask = basic.greedy_select(logits=comp_weights, mask=mask)\n",
    "            select_mask = select_mask.float()\n",
    "        select_mask_expand = select_mask.unsqueeze(2).expand_as(new_h)\n",
    "        select_mask_cumsum = select_mask.cumsum(1)\n",
    "        left_mask = 1 - select_mask_cumsum\n",
    "        left_mask_expand = left_mask.unsqueeze(2).expand_as(old_h_left)\n",
    "        right_mask = select_mask_cumsum - select_mask\n",
    "        right_mask_expand = right_mask.unsqueeze(2).expand_as(old_h_right)\n",
    "        new_h = (select_mask_expand * new_h\n",
    "                 + left_mask_expand * old_h_left\n",
    "                 + right_mask_expand * old_h_right)\n",
    "        new_c = (select_mask_expand * new_c\n",
    "                 + left_mask_expand * old_c_left\n",
    "                 + right_mask_expand * old_c_right)\n",
    "        selected_h = (select_mask_expand * new_h).sum(1)\n",
    "        return new_h, new_c, select_mask, selected_h\n",
    "    \n",
    "    def forward(self, input, length, return_select_masks=False):\n",
    "        max_depth = input.size(1)\n",
    "        length_mask = basic.sequence_mask(sequence_length=length,\n",
    "                                          max_length=max_depth)\n",
    "        select_masks = []\n",
    "        \n",
    "        state = self.word_linear(input)\n",
    "        state = state.chunk(chunks=2, dim=2)\n",
    "        nodes = []\n",
    "        for i in range(max_depth - 1):\n",
    "            h, c = state\n",
    "            l = (h[:, :-1, :], c[:, :-1, :])\n",
    "            r = (h[:, 1:, :], c[:, 1:, :])\n",
    "            new_state = self.treelstm_layer(l=l, r=r)\n",
    "            if i < max_depth - 2:\n",
    "                # We don't need to greedily select the composition in the\n",
    "                # last iteration, since it has only one option left.\n",
    "                new_h, new_c, select_mask, selected_h = self.select_composition(\n",
    "                    old_state=state, new_state=new_state,\n",
    "                    mask=length_mask[:, i+1:])\n",
    "                new_state = (new_h, new_c)\n",
    "                select_masks.append(select_mask)\n",
    "            done_mask = length_mask[:, i+1]\n",
    "            state = self.update_state(old_state=state, new_state=new_state,\n",
    "                                      done_mask=done_mask)\n",
    "        h, c = state\n",
    "\n",
    "        if not return_select_masks:\n",
    "            return h.squeeze(1), c.squeeze(1)\n",
    "        else:\n",
    "            return h.squeeze(1), c.squeeze(1), select_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.cuda.FloatTensor([[1,2,3],[2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
